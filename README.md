# LLM-driven Data Generation
Leverage LLMs to synthesize a Q/A dataset based on given text passages.
## Overview
This repository contains scripts and processes for LLM-driven data generation. It relies on vLLM as inference engine. 
Currently supported functionality:
- Generating questions about given text passages
- Generating answers to given questions about given text passages

## Setup
Install:
```bash
git clone https://github.com/dreichCSL/LLM_Data_Generation.git
cd llm_data_generation/
pip install -e .[gpu]
```

## Usage
Callable scripts are in `data_generation/scripts/`. Sample configuration files are in `configs/`. The config files act as examples, modify them for your use-case. 

### Data Generation
```bash
python data_generation/scripts/generate_text.py --config configs/config.yaml --output_dir output_questions --type questions
```
This script acts as entry point for various text generation processes. Select from the available process by specifying the `--type` (see also the help message of the script). Output will be written to the directory passed with `--output_dir`.

### Use Cases
Description of supported use cases.
1) Generate questions about given text passages:  
Generate (multiple) questions about each passage. This requires a file with text passages as context. A sample file can be found at `tests/data/sample_context.jsonl` and illustrates the format that the text passages should be given in. The output will be a jsonl file with one question per line. Number of generated questions per text passage depends on the richness of the passage itself and the max_tokens parameter in the used `config.yaml` (controls number of tokens that are generated by the LLM per text passage).
2) Generate answers to given questions about given text passages:  
Generate one answer to one question about one text passage. In addition to the needed text passages, this step also requires the question file (output of (1)). See `tests/data/sample_discourse_acts.jsonl` as an example. This file is passed to the script via `config.yaml` as `input_paths.discourse_file`.
